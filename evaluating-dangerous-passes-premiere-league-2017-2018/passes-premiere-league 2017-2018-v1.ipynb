{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit173fd16ddc3f4c069571a33c98898b00",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import FCPython \n",
    "# import statsmodels.api as sm\n",
    "# import statsmodels.formula.api as smf\n",
    "import sys\n",
    "# import seaborn as sns\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc,recall_score,precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "# from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/karim/staff/football_analytics/Wyscout/Wyscout/events/events_England.json') as f:\n",
    "    data = json.load(f)    \n",
    "raw = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "passes = raw[raw['eventName']=='Pass']\n",
    "passes = passes.sample(n = 50000, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Acc_pass', 'X_start', 'Y_start', 'C_start', \n",
    "        'X_end', 'Y_end', 'C_end', 'Distance_to_keep_start', \n",
    "        'Distance_to_keep_end', 'Distance_pass', 'match_period', \"speed\", \"X_start_squared\", \"Y_start_squared\", \"C_start_squared\", \"X_end_squared\", \"Y_end_squared\", \"C_end_squared\" ,\"playerId\"]\n",
    "pass_model = pd.DataFrame(columns=cols)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "25374     [{'y': 58, 'x': 68}, {'y': 33, 'x': 73}]\n490415    [{'y': 92, 'x': 90}, {'y': 39, 'x': 90}]\n142901    [{'y': 97, 'x': 35}, {'y': 75, 'x': 75}]\n336240    [{'y': 13, 'x': 32}, {'y': 32, 'x': 70}]\n320543    [{'y': 39, 'x': 13}, {'y': 90, 'x': 19}]\n                            ...                   \n238635    [{'y': 18, 'x': 94}, {'y': 69, 'x': 96}]\n467433    [{'y': 31, 'x': 29}, {'y': 30, 'x': 25}]\n220990    [{'y': 60, 'x': 12}, {'y': 71, 'x': 64}]\n328105    [{'y': 81, 'x': 26}, {'y': 39, 'x': 33}]\n554348    [{'y': 45, 'x': 45}, {'y': 75, 'x': 17}]\nName: positions, Length: 50000, dtype: object"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Created only for exploration purposes.\n",
    "passes_temp = passes.head(50000) # 50000\n",
    "passes_temp['positions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "50000it [16:10, 51.53it/s]\n"
    }
   ],
   "source": [
    "# Creating & preparing the dataset\n",
    "for i,pass_ in tqdm(passes.iterrows()):\n",
    "    \n",
    "    # Pass start location\n",
    "    pass_model.at[i,'X_start']=100-pass_['positions'][0]['x']\n",
    "    pass_model.at[i,'Y_start']=pass_['positions'][0]['y']\n",
    "    pass_model.at[i,'C_start']=abs(pass_['positions'][0]['y']-50)\n",
    "    \n",
    "    #Pass end location\n",
    "    pass_model.at[i,'X_end']=100-pass_['positions'][1]['x']\n",
    "    pass_model.at[i,'Y_end']=pass_['positions'][1]['y']\n",
    "    pass_model.at[i,'C_end']=abs(pass_['positions'][1]['y']-50)\n",
    "    pass_model.at[i, \"player_id\"] = pass_[\"playerId\"]\n",
    "    \n",
    "    ## squared \n",
    "    pass_model.at[i,'X_start_squared']=(100-pass_['positions'][0]['x'])**2\n",
    "    pass_model.at[i,'Y_start_squared']=(pass_['positions'][0]['y'])**2\n",
    "    pass_model.at[i,'C_start_squared']=(abs(pass_['positions'][0]['y']-50))**2\n",
    "\n",
    "    pass_model.at[i,'X*Y_start_squared']=(100-pass_['positions'][0]['x']) * (pass_['positions'][0]['y'])\n",
    "    \n",
    "    #Pass end location\n",
    "    pass_model.at[i,'X_end_squared']=(100-pass_['positions'][1]['x'])**2\n",
    "    pass_model.at[i,'Y_end_squared']=(pass_['positions'][1]['y'])**2\n",
    "    pass_model.at[i,'C_end_squared']=(abs(pass_['positions'][1]['y']-50))**2\n",
    "\n",
    "    pass_model.at[i,'X*Y_end_squared']= (100-pass_['positions'][1]['x']) * (pass_['positions'][1]['y'])\n",
    "    ## end squared\n",
    "    \n",
    "    #Distances (from the start location of the pass to the keep)\n",
    "    x_start=pass_model.at[i,'X_start']*105/100\n",
    "    y_start=pass_model.at[i,'C_start']*65/100\n",
    "    pass_model.at[i,'Distance_to_keep_start']=np.sqrt(x_start**2 + y_start**2)\n",
    "    \n",
    "    #Distances (from the end location of the pass to the keep)\n",
    "    x_end=pass_model.at[i,'X_end']*105/100\n",
    "    y_end=pass_model.at[i,'C_end']*65/100\n",
    "    pass_model.at[i,'Distance_to_keep_end']=np.sqrt(x_end**2 + y_end**2)\n",
    "    \n",
    "    #Pass distance\n",
    "    pass_model.at[i,'Distance_pass'] = np.sqrt(abs(x_start-x_end)**2 + abs(y_start-y_end)**2)\n",
    "    \n",
    "    pass_model.at[i, \"timeelapsed\"] = pass_[\"eventSec\"]\n",
    "    pass_model.at[i, \"match_period\"] = pass_[\"matchPeriod\"]\n",
    "        \n",
    "    #Accurate passes   \n",
    "    pass_model.at[i,'Acc_pass']=0\n",
    "    for passtags in pass_['tags']:\n",
    "        if passtags['id']==1801:\n",
    "            pass_model.at[i,'Acc_pass']=1\n",
    "    sys.stdout.write('.'); sys.stdout.flush(); #Just for visual check while the code is runnung, whether the loop works or not.\n",
    "\n",
    "# I added to more columns, which may come in handy while modelling. \n",
    "pass_model['dX'] = pass_model['X_start'] - pass_model['X_end']\n",
    "pass_model['d_Distance'] = pass_model['Distance_to_keep_start'] - pass_model['Distance_to_keep_end']\n",
    "pass_model[\"match_period\"] = pass_model[\"match_period\"].astype(\"category\").cat.codes\n",
    "pass_model = pass_model.astype(float)\n",
    "\n",
    "pass_model['speed'] = pass_model[\"dX\"] / pass_model[\"timeelapsed\"]\n",
    "# Turn them into floats as correlations cannot be plotted while all columns are objects.\n",
    "# Pass types are added from raw data.\n",
    "subEventName = passes['subEventName']\n",
    "pass_model = pass_model.join(subEventName)\n",
    "pass_model[\"subEventName\"] = pass_model[\"subEventName\"].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#condition: last third passes\n",
    "pass_model = pass_model[pass_model['Distance_to_keep_end'] < 33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing data for training\n",
    "pass_model2train = pass_model.drop([\"speed\", \"timeelapsed\"], axis=1)\n",
    "x_axis_dataframe = pass_model2train.drop([\"Acc_pass\", \"player_id\", \"playerId\"], axis=1)\n",
    "y_axis_dataframe = pass_model2train[\"Acc_pass\"]\n",
    "# to list in order preparing the input for sklearn\n",
    "x_axis_features = x_axis_dataframe.values.tolist() \n",
    "#normalisation\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler = scaler.fit(x_axis_features)\n",
    "x_axis_features = scaler.transform(x_axis_features)\n",
    "# to list in order preparing the input for sklearn\n",
    "y_axis_labels = y_axis_dataframe.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
    }
   ],
   "source": [
    "#linear regression training\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_axis_features, y_axis_labels, test_size=0.33)\n",
    "clf = LogisticRegression(random_state=0, max_iter=10000, tol=0.000001, verbose=1).fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7295965506621497"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "y_predictions = clf.predict(X_test)\n",
    "y_prediction_labels = list(zip(y_predictions, y_test))\n",
    "pred_correctness = [x[0] == x[1] for x in y_prediction_labels]\n",
    "accuracy_now = pred_correctness.count(True) / len(pred_correctness)\n",
    "# accuracy test blind\n",
    "accuracy_now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7191198786039453"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# testing on the training set to check if the model complexity needs to be increased\n",
    "y_predictions_train = clf.predict(X_train)\n",
    "y_prediction_labels_train = list(zip(y_predictions_train, y_train))\n",
    "pred_correctness_train = [x[0] == x[1] for x in y_prediction_labels_train]\n",
    "accuracy_now_train = pred_correctness_train.count(True) / len(pred_correctness_train)\n",
    "accuracy_now_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checked train and test accuracy -> found out that the train accuracy is 85%, so there is room for increasing the model's complexity -> I hearby keep checking the accuracy on test to make sure we are not falling into the curse of dimensionality aka overfitting\n",
    "\n",
    "# by normalizing the data 0-1 improved gradient descent and convergence\n",
    "\n",
    "# all features polynomial degree 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the coefficients\n",
    "list_of_coeffs_INIT = clf.coef_\n",
    "list_of_coeffs = [(x, y) for x,y in enumerate(list_of_coeffs_INIT[0])]\n",
    "list_of_coeffs2 = [(x, y) for x,y in enumerate(list_of_coeffs_INIT[0])]\n",
    "list_of_coeffs.sort(key= lambda x: x[1])\n",
    "list_of_coeffs2.sort(key= lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(10, -2.1113943669763193),\n (18, -1.0313563674400996),\n (4, -0.8957791071797098),\n (0, -0.862928919217068),\n (16, -0.7665215501290408),\n (14, -0.6933695114340648),\n (12, -0.6790331082107489),\n (6, -0.6251963963401043),\n (13, -0.5243464784091069),\n (19, -0.5243343398628163)]"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# negative coeffs\n",
    "list_of_coeffs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(8, 3.0399294859649526),\n (17, 1.8377409655463393),\n (20, 1.737648671714509),\n (3, 1.2682358521550252),\n (15, 0.7716477596419659),\n (5, 0.7072606896257371),\n (2, 0.3884148913252003),\n (1, 0.1747061818909441),\n (11, 0.014445560673396174),\n (9, 0.013634710768439114)]"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# positive coeffs\n",
    "list_of_coeffs2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['X_start', 'Y_start', 'C_start', 'X_end', 'Y_end', 'C_end',\n       'Distance_to_keep_start', 'Distance_to_keep_end', 'Distance_pass',\n       'match_period', 'X_start_squared', 'Y_start_squared', 'C_start_squared',\n       'X_end_squared', 'Y_end_squared', 'C_end_squared', 'X*Y_start_squared',\n       'X*Y_end_squared', 'dX', 'd_Distance', 'subEventName'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "#corresponding features to those coeffs\n",
    "x_axis_dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieving list of best player, worst players in the sample taken as well as their score according to my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_model_results = pass_model2train.drop([\"playerId\"], axis=1)\n",
    "distinct_player_ids = pass_model2train[\"player_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 467/467 [00:00<00:00, 494.03it/s]\n"
    }
   ],
   "source": [
    "#processing the IDs and their respective score in the model\n",
    "player_ids_to_scores = {}\n",
    "player_ids_to_scores_proba = {}\n",
    "player_ids_to_no_passes = {}\n",
    "player_ids_with_diffs = []\n",
    "for player_id in tqdm(distinct_player_ids):\n",
    "    temp_df = pass_model2train[pass_model2train[\"player_id\"] == player_id]\n",
    "    temp_df = temp_df.drop([\"player_id\", \"Acc_pass\", \"playerId\"], axis=1)\n",
    "    temp_vals = temp_df.values.tolist()\n",
    "    player_ids_to_no_passes[int(player_id)] = len(temp_vals)\n",
    "    temp_vals_scaled = scaler.transform(temp_vals)\n",
    "    y_predictions = clf.predict(temp_vals_scaled)\n",
    "    y_predictions_average = np.mean(y_predictions)\n",
    "    y_predictions_proba = clf.predict_proba(temp_vals_scaled)\n",
    "    y_predictions_average_proba = np.mean([x[1] for x in y_predictions_proba])\n",
    "    player_ids_to_scores[int(player_id)] = y_predictions_average\n",
    "    player_ids_to_scores_proba[int(player_id)] = y_predictions_average_proba\n",
    "    if (y_predictions_average_proba >= 0.5) != (y_predictions_average >= 0.5):\n",
    "        player_ids_with_diffs.append(player_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing the mapping (id <--> player Name)\n",
    "with open('/home/karim/staff/football_analytics/Wyscout/Wyscout/players.json') as f:\n",
    "    playersdata = json.load(f)\n",
    "player_name_to_id = {}\n",
    "player_id_to_name = {}\n",
    "all_player_data_w_id = {}\n",
    "for data_entry in playersdata:\n",
    "    player_name_to_id[data_entry[\"shortName\"]] = data_entry[\"wyId\"]\n",
    "    all_player_data_w_id[data_entry[\"wyId\"]] = data_entry\n",
    "    player_id_to_name[data_entry[\"wyId\"]] = data_entry[\"shortName\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve best and worst players and their model score\n",
    "id_to_score_tuple_list = [(x, y) for x,y in player_ids_to_scores_proba.items()]\n",
    "id_to_score_tuple_list2 = [(x, y) for x,y in player_ids_to_scores_proba.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve best 10 and worst 10 players and their model score\n",
    "id_to_score_tuple_list.sort(key=lambda x:x[1], reverse=False)\n",
    "id_to_score_tuple_list2.sort(key=lambda x:x[1], reverse=True)\n",
    "number_wanted = 10\n",
    "#id_to_score_tuple_list[:number_wanted] # top 10 worst players in passing (id, score)\n",
    "#id_to_score_tuple_list2[:number_wanted] # top 10 best players in passing (id, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1, 'P. Foden', 447205, 0.8687470937156003)\n(2, 'Brahim Diaz', 404397, 0.8564162931262473)\n(3, 'K. Stafylidis', 92947, 0.8367654000660716)\n(4, 'C. Tosun', 32636, 0.8274985749171635)\n(5, 'R. Barkley', 8246, 0.8215066313020184)\n(6, 'P. Mertesacker', 7856, 0.8207282801013299)\n(7, 'P. Jones', 7918, 0.8189403958911874)\n(8, 'N. Wells', 9179, 0.8159358824826997)\n(9, 'S. Kaikai', 297258, 0.8106025640136579)\n(10, 'I. Afellay', 3343, 0.8104130367890183)\n"
    }
   ],
   "source": [
    "#Top 10 --> top 10 best players in passing (id, score)\n",
    "top_players_info = [(rank+1, player_id_to_name[x[0]], x[0], x[1]) for rank, x in enumerate(id_to_score_tuple_list2[:number_wanted])] \n",
    "fbest = open('bestPlayers.txt', 'w')\n",
    "for listing in top_players_info:\n",
    "    print(listing)\n",
    "    fbest.write(\"\".join(str(listing)))\n",
    "    fbest.write(\"\\n\")\n",
    "fbest.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1, 'J. Hart', 8301, 0.19040813948480106)\n(2, 'E. Jakupovic', 93084, 0.20408590945642777)\n(3, 'F. Forster', 61941, 0.23487431376587295)\n(4, 'J. Murphy', 62091, 0.25036253480893617)\n(5, 'Ederson', 71654, 0.2520156676391796)\n(6, 'L. Grant', 8935, 0.2588606926423368)\n(7, 'Y. Kaboul', 8272, 0.3066054856575409)\n(8, '\\\\u0141. Fabia\\\\u0144ski', 7847, 0.30957300481769306)\n(9, 'H. Lloris', 25381, 0.3118138470959332)\n(10, 'M. Ryan', 61390, 0.32165116687017886)\n"
    }
   ],
   "source": [
    "worst_players_info = [(rank+1, player_id_to_name[x[0]], x[0], x[1]) for rank, x in enumerate(id_to_score_tuple_list[:number_wanted])] # top 10 best players in passing (id, score)\n",
    "#worst_players_names = []\n",
    "fworst = open('worstPlayers.txt', 'w')\n",
    "for listing in worst_players_info:\n",
    "    print(listing)\n",
    "    fworst.write(\"\".join(str(listing)))\n",
    "    fworst.write(\"\\ n\")\n",
    "    #worst_players_names = str(listing) + '\\n'\n",
    "fworst.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "M. Be\\u0161i\\u0107\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'passportArea': {'name': 'Bosnia-Herzegovina',\n  'id': 70,\n  'alpha3code': 'BIH',\n  'alpha2code': 'BA'},\n 'weight': 78,\n 'firstName': 'Muhamed',\n 'middleName': '',\n 'lastName': 'Be\\\\u0161i\\\\u0107',\n 'currentTeamId': 1620,\n 'birthDate': '1992-09-10',\n 'height': 177,\n 'role': {'code2': 'MD', 'code3': 'MID', 'name': 'Midfielder'},\n 'birthArea': {'name': 'Germany',\n  'id': 276,\n  'alpha3code': 'DEU',\n  'alpha2code': 'DE'},\n 'wyId': 14886,\n 'foot': 'right',\n 'shortName': 'M. Be\\\\u0161i\\\\u0107',\n 'currentNationalTeamId': 10001}"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "#check some players\n",
    "def retrievePlayerDetails(wanted_player_inquiry):\n",
    "    print(player_id_to_name[wanted_player_inquiry])\n",
    "    return all_player_data_w_id[wanted_player_inquiry]\n",
    "wanted_player_inquiry = 14886\n",
    "print(player_id_to_name[wanted_player_inquiry])\n",
    "all_player_data_w_id[wanted_player_inquiry]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}